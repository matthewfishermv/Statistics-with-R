outcome <- numeric(1000)
for (i in 1:1000) outcome[i] <- sample(temps, 10)
# Take 1000 samples from the temperature data.
outcome <- numeric(1000)
for (i in 1:1000) outcome[i] <- sample(temps, 10)
# Take 1000 samples from the temperature data.
outcome <- numeric(1000)
for (i in 1:1000) outcome[i] <- sample(temps, 1)
outcome
hist(outcomes)
hist(outcome)
mean(outcomes)
mean(outcome)
mean(temps)
# Take 1000 samples of size n=1 from the temperature data.
outcomes <- numeric(1000)
for (i in 1:1000) outcome[i] <- sample(temps, 1)
# Take 1000 samples of size n=1 from the temperature data.
outcomes <- numeric(1000)
for (i in 1:1000) outcomes[i] <- sample(temps, 1)
hist(outcomes)
par(mfrow=c(1, 1))
hist(outcomes)
# Take 1000 samples of size n=1 from the temperature data.
outcomes <- numeric(10000)
for (i in 1:10000) outcomes[i] <- sample(temps, 1)
par(mfrow=c(1, 1))
hist(outcomes)
# Take 1000 samples of size n=1 from the temperature data.
outcomes <- numeric(10000)
for (i in 1:10000) outcomes[i] <- mean(sample(temps, 30))
par(mfrow=c(1, 1))
hist(outcomes)
# Take 1000 samples of size n=1 from the temperature data.
outcomes <- numeric(10000)
for (i in 1:10000) outcomes[i] <- sample(temps, 1)
par(mfrow=c(1, 1))
hist(outcomes)
# Compare the mean of this sampling with the mean of the original data.
cat(mean(temps), mean(outcomes))
cat(sd(temps), sd(outcomes))
# Take 10,000 samples of size n=30 from the temperature data.
outcomes <- numeric(10000)
for (i in 1:10000) outcomes[i] <- sample(temps, 30)
# Take 10,000 samples of size n=30 from the temperature data.
outcomes <- numeric(10000)
for (i in 1:10000) outcomes[i] <- mean(sample(temps, 30))
hist(outcomes)
# Compare the mean of this sampling with the mean of the original data.
cat(mean(temps), mean(outcomes))
cat(sd(temps), sd(outcomes))
# Compare the varaibility of the original data and sampling data.
par(mfrow=c(1, 2))
hist(temps)
hist(outcomes)
hist(temps, main="Histogram of Temperatures", xlab="Temperature")
hist(outcomes, main="Histogram of Temperatures", xlab="Tempearture")
# Compare the variability of the original data and sampling data.
par(mfrow=c(1, 2))
hist(temps, main="Histogram of Temperatures", xlab="Temperature")
hist(outcomes, main="Histogram of Temperatures", xlab="Temperature")
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n")
par(mfrow=c(1, 1))
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n")
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n")
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n")
# Shade 2.5% of the area under each tail.
polygon(c(-5, seq(-5, -1.96, by=0.01), -1.96),
c(0, dnorm(seq(-5, -1.96, by=0.01)), 0),
col="tomato2", border="tomato2")
polygon(c(1.96, seq(1.96, 5, by=0.01), 5),
c(0, dnorm(seq(1.96, 5, by=0.01)), 0),
col="tomato2", border="tomato2")
# Add the distribution curve.
lines(x, y, lwd=2)
# Add labels.
arrows(-1.96, 0.025, 1.96, 0.025, code=3)
text(0, 0.04, expression(1-alpha), adj=0.5)
lines(c(-2.4, -3), c(0.01, 0.1))
text(-3, 0.13, expression(frac(alpha, 2)), adj=0.5)
lines(c(2.4, 3), c(0.01, 0.1))
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l")
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", main="Normal Distribution")
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", main="Normal Distribution")
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", lwd=2, main="Normal Distribution")
# Generate 100 data points from the uniform distribution with a mean of 10.6
# and a standard deviation of 2.9.
x <- runif(100)
# Generate 100 data points from the uniform distribution.
x <- runif(100)
# Summarize the data (numerically).
mean(x)
sd(x)
range(x)
summary(x)
# Summarize the data (graphically).
hist(x)
hist(x, breaks=0:22)
boxplot(x)
# Develop a sampling experiment that will take n samples of size sample.size and
# plot it on a histogram.
do.experiment <- function(n, sample.size=30) {
means <- numeric(n)
for (i in 1:n) {
means[i] <- mean(sample(x, size=sample.size))
}
hist(means, xlim=c(9, 12), ylim=c(0, 1), freq=FALSE,
col="steelblue3", border="steelblue4")
# Add a normal distribution curve.
x <- seq(5, 16, by=0.1)
y <- dnorm(x, mean=mean(means), sd=sd(means))
lines(x, y, col="tomato2")
# Add a mean line.
abline(v=mean(means), lty=3, col="tomato2")
}
# Run the experiment with different numbers of samples.
par(mfrow=c(2, 2))
do.experiment(10)
do.experiment(30)
do.experiment(1000)
do.experiment(10000)
means
n <- 30
means <- numeric(n)
for (i in 1:n) {
means[i] <- mean(sample(x, size=sample.size))
}
sample.size <- 30
means <- numeric(n)
for (i in 1:n) {
means[i] <- mean(sample(x, size=sample.size))
}
hist(means, xlim=c(9, 12), ylim=c(0, 1), freq=FALSE,
col="steelblue3", border="steelblue4")
means
mean(means)
means <- numeric(N)
means <- numeric(n)
means
for (i in 1:n) {
means[i] <- mean(sample(x, size=sample.size))
}
means
x
# Generate 100 data points from the uniform distribution.
x <- runif(100) * 100
x
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
means
means <- numeric(n)
for (i in 1:n) {
means[i] <- mean(sample(x, size=sample.size))
}
means
mean(means)
hist(means)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
means <- numeric(n)
for (i in 1:n) {
means[i] <- mean(sample(x, size=sample.size))
}
hist(means, xlim=c(9, 12), freq=FALSE,
col="steelblue3", border="steelblue4")
means
hist(means)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
means <- numeric(n)
for (i in 1:n) {
means[i] <- mean(sample(x, size=sample.size))
}
hist(means, freq=FALSE,
col="steelblue3", border="steelblue4",
main=paste("Distribution of Sample Means (", n, " samples)", sep=""),
xlab="Means")
# Add a normal distribution curve.
x <- seq(5, 16, by=0.1)
y <- dnorm(x, mean=mean(means), sd=sd(means))
lines(x, y, col="tomato2")
x
y
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Central-Limit-Theorem.R', echo=TRUE)
# Visualize the 68-95-99.7 Rule.
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", lwd=2, main="Normal Distribution")
par(mfrow=c(1,1))
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
# Visualize the 68-95-99.7 Rule.
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", lwd=2, main="Normal Distribution")
# Visualize the 68-95-99.7 Rule.
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n", lwd=2, main="Normal Distribution")
# Visualize the 68-95-99.7 Rule.
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n", lwd=2, main="The 68%-95%-99.7% RUle")
# Visualize the 68-95-99.7 Rule.
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n", lwd=2, main="The 68%-95%-99.7% Rule")
standard.deviation <- sd(y)
abline(v=mean(y) - sd(y))
abline(v-mean(y) + sd(y))
abline(v=mean(y) + sd(y))
abline(v=mean(y) - 2 * sd(y))
abline(v=mean(y) + 2 * sd(y))
abline(v=mean(y) - 3 * sd(y))
abline(v=mean(y) + 3 * sd(y))
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", lwd=2, main="Normal Distribution")
# Visualize the 68-95-99.7 Rule.
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", lwd=2, main="The 68%-95%-99.7% Rule")
abline(v=mean(y) - sd(y))
abline(v=mean(y) + sd(y))
abline(v=mean(y) - 2 * sd(y))
abline(v=mean(y) + 2 * sd(y))
abline(v=mean(x) - sd(x))
abline(v=mean(x) + sd(x))
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
y
mean(y)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
abline(v=mean(y) - (2 * sd(y)))
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
# Visualize the 68-95-99.7 Rule.
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="l", lwd=2, main="The 68%-95%-99.7% Rule")
# Visualize the 68-95-99.7 Rule.
plot(x, y, xlab="", ylab="", type="l", lwd=2, main="The 68%-95%-99.7% Rule")
abline(v=mean(y) - sd(y))
abline(v=mean(y) + sd(y))
sd(y)
mean(y) - sd(y)
y
x
sd(x)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
abline(v=mean(x) - sd(x))
abline(v=mean(x) + sd(x))
sd(x)
# Visualize the 68-95-99.7 Rule.
x <- seq(-10, 10, by=0.1)
y <- dnorm(x)
plot(x, y, xlab="", ylab="", type="l", lwd=2, main="The 68%-95%-99.7% Rule")
abline(v=mean(x) - sd(x))
abline(v=mean(x) + sd(x))
abline(v=mean(x) - (2 * sd(x)))
abline(v=mean(x) + (2 * sd(x)))
abline(v=mean(x) - (3 * sd(x)))
abline(v=mean(x) + (3 * sd(x)))
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
mean(y)
sd(y)
mean(y) - sd(y)
mean(y) + sd(y)
abline(v=mean(y)*10 - sd(y)*10)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
y
mean(y)
sd(y)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
mean(y)
sd(y)
2*sd(y)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
mean(y) - sd(y)
mean(y) + sd(y)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
# Visualize the 68-95-99.7 Rule.
plot(x, y, xlab="", ylab="", type="l", lwd=2, main="The 68-95-99.7 Rule")
abline(v=mean(y) - sd(y))
abline(v=mean(y) + sd(y))
mean(y)
mean(y) - sd(y)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Distributions.R', echo=TRUE)
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n")
# Shade 2.5% of the area under each tail.
polygon(c(-5, seq(-5, -1.96, by=0.01), -1.96),
c(0, dnorm(seq(-5, -1.96, by=0.01)), 0),
col="tomato2", border="tomato2")
polygon(c(1.96, seq(1.96, 5, by=0.01), 5),
c(0, dnorm(seq(1.96, 5, by=0.01)), 0),
col="tomato2", border="tomato2")
# Add the distribution curve.
lines(x, y, lwd=2)
# Add labels.
arrows(-1.96, 0.025, 1.96, 0.025, code=3)
text(0, 0.04, expression(1-alpha), adj=0.5)
lines(c(-2.4, -3), c(0.01, 0.1))
text(-3, 0.13, expression(frac(alpha, 2)), adj=0.5)
lines(c(2.4, 3), c(0.01, 0.1))
text(3, 0.13, expression(frac(alpha, 2)), adj=0.5)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
# Example: Confidence interval for infant birth weights.
qnorm(0.25, mean=3400, sd=395)
qnorm(0.025, mean=3400, sd=395)
# Example: Confidence interval for infant birth weights.
qnorm(0.025, mean=3400, sd=395)
qnorm(0.025, mean=3400, sd=395)
qnorm(0.025, mean=3400, sd=395, lower.tail=FALSE)
# Example: Confidence interval for infant birth weights.
qnorm(0.025, mean=3400, sd=395)
qnorm(0.025, mean=3400, sd=395, lower.tail=FALSE)
# Example: Confidence interval for infant birth weights.
qnorm(0.025)
qnorm(0.025, lower.tail=FALSE)
# Example: Confidence interval for infant birth weights.
z.lower <- qnorm(0.025)
z.upper <- qnorm(0.025, lower.tail=FALSE)
3400 - 1.96*(395/sqrt(150))
3400 + 1.96*(395/sqrt(150))
c(3400 - 1.96*(395/sqrt(150)),
3400 + 1.96*(395/sqrt(150)))
qnorm(0.25, mean=3400, sd=395)
# Visualize the infant birth weights example.
x <- seq(3100, 3700, by=1)
y <- dnorm(x, mean=3400, sd=395)
plot(x, y)
# Visualize the infant birth weights example.
x <- seq(3000, 3800, by=1)
y <- dnorm(x, mean=3400, sd=395)
plot(x, y)
# Visualize the infant birth weights example.
x <- seq(1400, 5400, by=1)
y <- dnorm(x, mean=3400, sd=395)
plot(x, y)
plot(x, y, type="l", lwd=2)
# Visualize the infant birth weights example.
x <- seq(2400, 4400, by=1)
y <- dnorm(x, mean=3400, sd=395)
plot(x, y, type="l", lwd=2)
abline(v=3400)
abline(v=3400, lty=2)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
abline(v=3400, lty=2, col="tomato2")
abline(v=3400, lty=2)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
abline(z.lower)
abline(v=z.lower)
z.lower
abline((3400 - 1.96*(395/sqrt(150)))
abline(v=(3400 - 1.96*(395/sqrt(150))))
abline(v=(3400 - 1.96*(395/sqrt(150))))
abline(v=(3400 - 1.96*(395/sqrt(150))))
abline(v=(3400 + 1.96*(395/sqrt(150))))
plot(x, y, type="l", lwd=2, main="Infant Birth Weights - 95% Confidence Interval")
abline(v=3400, lty=2)
abline(v=(3400 - 1.96*(395/sqrt(150))))
abline(v=(3400 + 1.96*(395/sqrt(150))))
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n",
main="Confidence Levels and Signficance Levels")
# Shade 2.5% of the area under each tail.
polygon(c(-5, seq(-5, -1.96, by=0.01), -1.96),
c(0, dnorm(seq(-5, -1.96, by=0.01)), 0),
col="tomato2", border="tomato2")
polygon(c(1.96, seq(1.96, 5, by=0.01), 5),
c(0, dnorm(seq(1.96, 5, by=0.01)), 0),
col="tomato2", border="tomato2")
# Add the distribution curve.
lines(x, y, lwd=2)
# Add labels.
arrows(-1.96, 0.025, 1.96, 0.025, code=3)
text(0, 0.04, expression(1-alpha), adj=0.5)
lines(c(-2.4, -3), c(0.01, 0.1))
text(-3, 0.13, expression(frac(alpha, 2)), adj=0.5)
lines(c(2.4, 3), c(0.01, 0.1))
text(3, 0.13, expression(frac(alpha, 2)), adj=0.5)
text(0, 0.04, expression(1-alpha), adj=0.5, cex=2)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n",
main="Confidence Levels and Signficance Levels")
# Shade 2.5% of the area under each tail.
polygon(c(-5, seq(-5, -1.96, by=0.01), -1.96),
c(0, dnorm(seq(-5, -1.96, by=0.01)), 0),
col="tomato2", border="tomato2")
polygon(c(1.96, seq(1.96, 5, by=0.01), 5),
c(0, dnorm(seq(1.96, 5, by=0.01)), 0),
col="tomato2", border="tomato2")
# Add the distribution curve.
lines(x, y, lwd=2)
# Add labels.
arrows(-1.96, 0.025, 1.96, 0.025, code=3)
text(0, 0.04, expression(1-alpha), adj=0.5, cex=2)
lines(c(-2.4, -3), c(0.01, 0.1))
text(-3, 0.13, expression(frac(alpha, 2)), adj=0.5, cex=2)
lines(c(2.4, 3), c(0.01, 0.1))
text(3, 0.13, expression(frac(alpha, 2)), adj=0.5, cex=2)
# Draw a normal distribution plot.
x <- seq(-5, 5, by=0.1)
y <- dnorm(x)
plot(x, y, xaxt="n", yaxt="n", xlab="", ylab="", type="n",
main="Confidence Levels and Signficance Levels")
# Shade 2.5% of the area under each tail.
polygon(c(-5, seq(-5, -1.96, by=0.01), -1.96),
c(0, dnorm(seq(-5, -1.96, by=0.01)), 0),
col="tomato2", border="tomato2")
polygon(c(1.96, seq(1.96, 5, by=0.01), 5),
c(0, dnorm(seq(1.96, 5, by=0.01)), 0),
col="tomato2", border="tomato2")
# Add the distribution curve.
lines(x, y, lwd=2)
# Add labels.
arrows(-1.96, 0.025, 1.96, 0.025, code=3)
text(0, 0.04, expression(1-alpha), adj=0.5, cex=1.5)
lines(c(-2.4, -3), c(0.01, 0.1))
text(-3, 0.13, expression(frac(alpha, 2)), adj=0.5, cex=1.5)
lines(c(2.4, 3), c(0.01, 0.1))
text(3, 0.13, expression(frac(alpha, 2)), adj=0.5, cex=1.5)
c(3400 - z.upper*(395/sqrt(150)),
3400 + z.upper*(395/sqrt(150)))
abline(v=(3400 - z.upper*(395/sqrt(150))))
abline(v=(3400 + z.upper*(395/sqrt(150))))
z.lower <- qnorm(0.025)
z.upper <- qnorm(0.025, lower.tail=FALSE)
c(3400 - z.upper*(395/sqrt(150)),
3400 + z.upper*(395/sqrt(150)))
# Visualize the infant birth weights example.
x <- seq(2400, 4400, by=1)
y <- dnorm(x, mean=3400, sd=395)
plot(x, y, type="l", lwd=2,
main="Infant Birth Weights - 95% Confidence Interval", xlab="Weight", ylab="")
abline(v=3400, lty=2)
abline(v=(3400 - z.upper*(395/sqrt(150))))
abline(v=(3400 + z.upper*(395/sqrt(150))))
# Example: Confidence interval for infant birth weights.
z.upper <- qnorm(0.025, lower.tail=FALSE)
c(3400 - z.upper*(395/sqrt(150)),
3400 + z.upper*(395/sqrt(150)))
# Example: Confidence interval for infant birth weights.
z.upper <- qnorm(0.025, mean=3400, sd=395, lower.tail=FALSE)
c(3400 - z.upper*(395/sqrt(150)),
3400 + z.upper*(395/sqrt(150)))
# Visualize the infant birth weights example.
x <- seq(2400, 4400, by=1)
y <- dnorm(x, mean=3400, sd=395)
plot(x, y, type="l", lwd=2,
main="Infant Birth Weights - 95% Confidence Interval", xlab="Weight", ylab="")
abline(v=3400, lty=2)
abline(v=(3400 - z.upper*(395/sqrt(150))))
abline(v=(3400 + z.upper*(395/sqrt(150))))
# Example: Confidence interval for infant birth weights.
z.upper <- qnorm(0.025, lower.tail=FALSE)
c(3400 - z.upper*(395/sqrt(150)),
3400 + z.upper*(395/sqrt(150)))
# Visualize the infant birth weights example.
x <- seq(2400, 4400, by=1)
y <- dnorm(x, mean=3400, sd=395)
plot(x, y, type="l", lwd=2,
main="Infant Birth Weights - 95% Confidence Interval", xlab="Weight", ylab="")
abline(v=3400, lty=2)
abline(v=(3400 - z.upper*(395/sqrt(150))))
abline(v=(3400 + z.upper*(395/sqrt(150))))
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
z.upper
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
source('C:/Users/mfisher/OneDrive/Projects/Software/Statistics/Hypothesis-Testing/Hypothesis-Testing.R', echo=TRUE)
